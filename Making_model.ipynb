{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "  # For stemming purpose\n",
    "from nltk.stem import PorterStemmer\n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\PROJECTS\\Movie-recommender-system\\\\finalData\\\\final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York Doll</td>\n",
       "      <td>A recovering alcoholic and recently converted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mickey's Magical Christmas: Snowed in at the H...</td>\n",
       "      <td>After everyone is snowed in at the House of Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mickey's House of Villains</td>\n",
       "      <td>The villains from the popular animated Disney ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And Then I Go</td>\n",
       "      <td>In the cruel world of junior high, Edwin suffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Extremely Goofy Movie</td>\n",
       "      <td>It's a big time in Max's life. He's college bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   \n",
       "0                                      New York Doll  \\\n",
       "1  Mickey's Magical Christmas: Snowed in at the H...   \n",
       "2                         Mickey's House of Villains   \n",
       "3                                      And Then I Go   \n",
       "4                           An Extremely Goofy Movie   \n",
       "\n",
       "                                                tags  \n",
       "0  A recovering alcoholic and recently converted ...  \n",
       "1  After everyone is snowed in at the House of Mo...  \n",
       "2  The villains from the popular animated Disney ...  \n",
       "3  In the cruel world of junior high, Edwin suffe...  \n",
       "4  It's a big time in Max's life. He's college bo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying the NLP transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perform stemming to reduce the corpus size and get root words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    l = []\n",
    "    for i in text.split():\n",
    "        l.append(ps.stem(i))\n",
    "\n",
    "    return \" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now perform text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=13260,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_vector = cv.fit_transform(df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13260, 13260)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(movie_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.02948839, ..., 0.02864166, 0.11566299,\n",
       "        0.09430419],\n",
       "       [0.        , 1.        , 0.34641016, ..., 0.01869241, 0.03774257,\n",
       "        0.        ],\n",
       "       [0.02948839, 0.34641016, 1.        , ..., 0.01942572, 0.03922323,\n",
       "        0.02132007],\n",
       "       ...,\n",
       "       [0.02864166, 0.01869241, 0.01942572, ..., 1.        , 0.03809697,\n",
       "        0.04141577],\n",
       "       [0.11566299, 0.03774257, 0.03922323, ..., 0.03809697, 1.        ,\n",
       "        0.0836242 ],\n",
       "       [0.09430419, 0.        , 0.02132007, ..., 0.04141577, 0.0836242 ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['title'] == 'The Lego Movie'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    index = df[df['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])),reverse=True,key = lambda x: x[1])\n",
    "    for i in distances[1:6]:\n",
    "        print(df.iloc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iron Man 3\n",
      "Captain America: Civil War\n",
      "Iron Man 2\n",
      "Being Flynn\n",
      "The Survivalist\n"
     ]
    }
   ],
   "source": [
    "recommend('The Avengers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_1.pkl\n",
      "Chunk 2 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_2.pkl\n",
      "Chunk 3 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_3.pkl\n",
      "Chunk 4 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_4.pkl\n",
      "Chunk 5 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_5.pkl\n",
      "Chunk 6 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_6.pkl\n",
      "Chunk 7 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_7.pkl\n",
      "Chunk 8 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_8.pkl\n",
      "Chunk 9 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_9.pkl\n",
      "Chunk 10 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_10.pkl\n",
      "Chunk 11 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_11.pkl\n",
      "Chunk 12 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_12.pkl\n",
      "Chunk 13 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_13.pkl\n",
      "Chunk 14 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_14.pkl\n",
      "Chunk 15 saved as D:\\PROJECTS\\Movie-recommender-system\\streamLitWebApp\\similarity_chunk_15.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming similarity is your similarity dataset\n",
    "# Calculate the number of chunks to divide the dataset into\n",
    "num_chunks = 15\n",
    "chunk_size = len(similarity) // num_chunks\n",
    "\n",
    "# Specify the directory where you want to save the chunked .pkl files\n",
    "output_dir = 'D:\\\\PROJECTS\\\\Movie-recommender-system\\\\streamLitWebApp'\n",
    "\n",
    "# Iterate over the chunks and save each chunk separately\n",
    "for i in range(num_chunks):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = start_idx + chunk_size\n",
    "    if i == num_chunks - 1:\n",
    "        # Last chunk may have different size if the dataset size is not divisible by num_chunks\n",
    "        chunk_data = similarity[start_idx:]\n",
    "    else:\n",
    "        chunk_data = similarity[start_idx:end_idx]\n",
    "\n",
    "    # Save the chunk as a .pkl file in the specified directory\n",
    "    filename = os.path.join(output_dir, f'similarity_chunk_{i+1}.pkl')\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(chunk_data, f)\n",
    "\n",
    "    print(f'Chunk {i+1} saved as {filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = 'D:\\\\PROJECTS\\\\Movie-recommender-system\\\\streamLitWebApp'\n",
    "filename = os.path.join(output_dir, 'movies.pkl')\n",
    "\n",
    "# Assuming df is your DataFrame containing movie data\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
